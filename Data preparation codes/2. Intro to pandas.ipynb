{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module we will start with the fabled python package named pandas which has become defacto tool for handling datasets in python. In this videos we will look at following aspects of pandas \n",
    "\n",
    "1. Manually creating data frames \n",
    "2. Reading data from external file\n",
    "3. peripheral summary of the data\n",
    "4. subsetting on the basis of rownumber , colnumber \n",
    "5. subsetting on the basis of condition \n",
    "6. subsetting on the basis of column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets import the package first and then we will create dataframes manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are two ways to create dataframes from list of values as columns . Lets first create some lists values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age=np.random.randint(low=16,high=80,size=[20,])\n",
    "city=np.random.choice(['Mumbai','Delhi','Chennai','Kolkata'],20)\n",
    "default=np.random.choice([0,1],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can zip these to convert them to single list of tuples , each tuple in that list will correspond to a row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata=list(zip(age,city,default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=mydata,columns=['age','city','default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to put them in a dictionary , you will not need to supply column names separately in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'age':age,'city':city,'default':default})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just the process of creating them is different , there is no difference in properties of end result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can read data from external file very easily using function read_csv from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file=r'/Users/lalitsachan/Dropbox/PDS V3/Data/loans data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here r is added at the begning of the path to file to make it a raw string , so that its treated as path as is and any special oocurences are not interpreted as their special meaning by python. For example \\n means newline , which will be ignored when we add r at the beginning of the string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to view first few obs of the data we can write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get column names we can look attribute column of the data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see type of these columns we can use attribute dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flost64 here correponds to numeric values and object corresponds to categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to know how many rows and columns are their in the data we can use attribute shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tells us that the data has 2500 rows/observations and 15 columns in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets subset this data on the basis of row and column numbers , keep in mind that count start with 0 for both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld1=ld.iloc[3:7,1:5]\n",
    "ld1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iloc here correponds to subsetting by position , to understand this better lets try to further subset this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld1.iloc[2:4,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see here the position is relative to current data , not the original one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally however we do not subset data by positions , we subset by either conditions or column names , if we are subsetting just on the basis of conditions or just column names we can directly pass those in square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[(ld['Home.Ownership']=='MORTGAGE') & (ld['Monthly.Income']>5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a single column name can be directly passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['Home.Ownership']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "however mulitple column names need to be passed as a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[['Home.Ownership','Monthly.Income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when using both condition and column names we need to use .loc with dataframe name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.loc[(ld['Home.Ownership']=='MORTGAGE') & (ld['Monthly.Income']>5000),['Home.Ownership','Monthly.Income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do keep in mind that the accessed elements in these ways can also be modified by equating them to appropriate replacement to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to negate a condition or drop rows on the basis of a conditon , we just need to add a ~ symbol in front of the condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[~((ld['Home.Ownership']=='MORTGAGE') & (ld['Monthly.Income']>5000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to drop columns on the basis of names we can make use of the inbuilt drop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.drop(['Home.Ownership','Monthly.Income'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you scroll through the output you will find that those columns are no more in the data, this however doesnt modify the original data , these columns are still present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can equate the output to original data name in order to change it , like this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld=ld.drop(['Home.Ownership','Monthly.Income'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you can make use of the inplace option in the drop function to change the data inplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld.drop(['Debt.To.Income.Ratio', 'State'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this changes the data inplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice that those columns are not there in the data inmore , one more thing that you need to be careful with here is that when using inplace=True option, function drop doesnt output anything so dont equate it to original data. if you do original data will end becoming a None type object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to delete a column is to use keyword del , the same one which we used in context of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ld['Employment.Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will stop our dicsusion on pandas dataframe in this video. In the next video , we will see how to add new columns , and modify existing columns in the data. We will also see how to check , count and impute missing value in the data. See you in the next video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
